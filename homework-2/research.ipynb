{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Small Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Encoder(tokens=2, sample=['action', 'comedy'])\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from src.encoder import Encoder\n",
    "\n",
    "labeler = Encoder(['action', 'comedy'])\n",
    "print(labeler)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder(tokens=7, sample=['fun', 'shoot', 'fast', 'couple', 'love', 'fly', 'furious'])\n"
     ]
    }
   ],
   "source": [
    "vocabulary = Encoder.open('movie-review-small/aclImdb/imdb.vocab')\n",
    "print(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the train corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fun': 1, 'couple': 1, 'love': 2} comedy\n",
      "{'couple': 1, 'fly': 1, 'fast': 1, 'fun': 2} comedy\n",
      "{'fast': 1, 'furious': 1, 'shoot': 1} action\n",
      "{'fly': 1, 'fast': 1, 'shoot': 1, 'love': 1} action\n",
      "{'furious': 1, 'shoot': 2, 'fun': 1} action\n"
     ]
    }
   ],
   "source": [
    "from src.structures.corpus import Corpus\n",
    "from src.structures.document import Document\n",
    "\n",
    "train_corpus = Corpus.open('movie-review-small/aclImdb/train/**/*.txt', vocabulary=vocabulary, verbose=True)\n",
    "\n",
    "for document, label in zip(train_corpus, train_corpus.labels()):\n",
    "    print(document, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the corpus\n",
    "\n",
    "frequencies+label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus.write('movie-review-small/aclImdb/train.NB', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c(C)   | value\n",
      "-------+------\n",
      "action |     3\n",
      "comedy |     2\n",
      "log_2(p(C)) | value\n",
      "------------+------\n",
      "action      |  None\n",
      "comedy      |  None\n",
      "c(t,C) | fun | shoot | fast | couple | love | fly | furious\n",
      "-------+-----+-------+------+--------+------+-----+--------\n",
      "action |   1 |     4 |    2 |      0 |    1 |   1 |       2\n",
      "comedy |   3 |     0 |    1 |      2 |    2 |   1 |       0\n",
      "log_2(P(t|C)) |  fun | shoot | fast | couple | love |  fly | furious\n",
      "--------------+------+-------+------+--------+------+------+--------\n",
      "       action | None |  None | None |   None | None | None |    None\n",
      "       comedy | None |  None | None |   None | None | None |    None\n"
     ]
    }
   ],
   "source": [
    "from src.model import Model\n",
    "\n",
    "model = Model(vocabulary, labeler, log=True)\n",
    "model.fit(train_corpus, train_corpus.labels())\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and save the test corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fast': 1, 'couple': 1, 'shoot': 1, 'fly': 1} action\n"
     ]
    }
   ],
   "source": [
    "test_corpus = Corpus.open('movie-review-small/aclImdb/test/**/*.txt', vocabulary=vocabulary, verbose=True)\n",
    "test_corpus.write('movie-review-small/aclImdb/test.NB', verbose=True)\n",
    "\n",
    "for document, label in zip(test_corpus, test_corpus.labels()):\n",
    "    print(document, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p(C|d) |              value\n",
      "-------+-------------------\n",
      "action | 1.2111111111111112\n",
      "comedy |                0.9\n",
      "predict(Corpus(documents=1, tokens=4, words=4))) [0] ['action']\n",
      "accuracy 1.0\n",
      "Confusion | action | comedy\n",
      "----------+--------+-------\n",
      "   action |      1 |      0\n",
      "   comedy |      0 |      0\n"
     ]
    }
   ],
   "source": [
    "from src.metrics import Metrics\n",
    "\n",
    "predictions = model.predict(test_corpus, verbose=True, debug=True)\n",
    "print(f'predict({test_corpus})', predictions, labeler.decode(predictions))\n",
    "score = Metrics.score(test_corpus.labels(), labeler.decode(predictions), labeler)\n",
    "print('accuracy', score['accuracy'])\n",
    "print(score['confusion'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the model again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c(C)   | value\n",
      "-------+------\n",
      "action |     3\n",
      "comedy |     2\n",
      "log_2(p(C)) |               value\n",
      "------------+--------------------\n",
      "action      | -0.7369655941662062\n",
      "comedy      | -1.3219280948873622\n",
      "c(t,C) | fun | shoot | fast | couple | love | fly | furious\n",
      "-------+-----+-------+------+--------+------+-----+--------\n",
      "action |   1 |     4 |    2 |      0 |    1 |   1 |       2\n",
      "comedy |   3 |     0 |    1 |      2 |    2 |   1 |       0\n",
      "log_2(P(t|C)) |  fun |             shoot |               fast |             couple | love |                 fly | furious\n",
      "--------------+------+-------------------+--------------------+--------------------+------+---------------------+--------\n",
      "       action | None | -1.84799690655495 | -2.584962500721156 | -4.169925001442313 | None | -3.1699250014423126 |    None\n",
      "       comedy | None |              -4.0 |               -3.0 | -2.415037499278844 | None |                -3.0 |    None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import text_helpers\n",
    "\n",
    "acronyms, smileys, positive_words, negative_words, negations, stopwords = text_helpers(labeler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a raw review from the corpus\n",
    "\n",
    "```\n",
    "Airwolf The Movie, A variation on the original 2 part pilot, Yet the movie although shorter, does contain extra footage Unseen in the 2 hour pilot The pilot is much more of a pilot than the movie Where as a pilot movie is normally the same (2 parter combined) But the movie is actually a different edit with extras here and cuts there.<br /><br />Worth a look, even if you have the season 1 DVD set, I'd still pick up a copy of the \"movie\" It's still in some shops like virgin, Woolworths and the likes of mixed media stores, although it generally needs ordering, But it saves needing to buy online (as many of us still don't do or trust online shopping) but if you look around airwolfs in stores<br /><br />Airwolf was truly 1 of the 80's most under rated shows.<br /><br />A full size Airwolf is currently being re-built for a Helicopter Museum :) Info and work in progress pictures are over at http://Airwolf.org Also with Airwolf Mods for Flashpoint and Flight Sim Games It seams she's finally here to stay :)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'airwolf': 4, 'movie,': 1, 'a': 8, 'variation': 1, 'original': 1, 'part': 1, 'pilot,': 1, 'movie': 4, 'shorter,': 1, 'extra': 1, 'footage': 1, 'unseen': 1, 'hour': 1, 'pilot': 4, '(2': 1, 'parter': 1, 'combined)': 1, 'edit': 1, 'extras': 1, 'cuts': 1, 'there.': 1, 'comedy': 8, 'look,': 1, 'season': 1, '1': 2, 'dvd': 1, 'set,': 1, 'pick': 1, 'copy': 1, '\"movie\"': 1, 'shops': 1, 'virgin,': 1, 'woolworths': 1, 'mixed': 1, 'media': 1, 'stores,': 1, 'generally': 1, 'ordering,': 1, 'saves': 1, 'needing': 1, 'buy': 1, 'online': 2, '(as': 1, '||not||': 1, 'shopping)': 1, 'airwolfs': 1, 'stores': 1, \"80's\": 1, 'rated': 1, 'shows.': 1, 'full': 1, 'size': 1, 're-built': 1, 'helicopter': 1, 'museum': 1, 'info': 1, 'pictures': 1, '||url||': 1, 'mods': 1, 'flashpoint': 1, 'flight': 1, 'sim': 1, 'games': 1, 'seams': 1, 'finally': 1, 'stay': 1}\n"
     ]
    }
   ],
   "source": [
    "from src.structures.bag_of_words import BagOfWords\n",
    "\n",
    "bow = BagOfWords.open(\n",
    "    'movie-review-HW2/aclImdb/train/pos/6770_10.txt',\n",
    "    expansions=acronyms,\n",
    "    replacements={ **smileys, **positive_words, **negative_words, **negations},\n",
    "    ignored=stopwords,\n",
    "    verbose=False)\n",
    "print(bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and saving training data\n",
    "\n",
    "This may take a while, depending on the size of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder(tokens=89527, sample=['worships', 'macnee', 'air-conditioning', 'defends', 'protocols', 'filicide'])\n",
      "1000 documents loaded\n",
      "2000 documents loaded\n",
      "3000 documents loaded\n",
      "4000 documents loaded\n",
      "5000 documents loaded\n",
      "6000 documents loaded\n",
      "7000 documents loaded\n",
      "8000 documents loaded\n",
      "9000 documents loaded\n",
      "10000 documents loaded\n",
      "11000 documents loaded\n",
      "12000 documents loaded\n",
      "13000 documents loaded\n",
      "14000 documents loaded\n",
      "15000 documents loaded\n",
      "16000 documents loaded\n",
      "17000 documents loaded\n",
      "18000 documents loaded\n",
      "19000 documents loaded\n",
      "20000 documents loaded\n",
      "21000 documents loaded\n",
      "22000 documents loaded\n",
      "23000 documents loaded\n",
      "24000 documents loaded\n",
      "Corpus(documents=25000, tokens=87884, words=5871238))\n",
      "1000 documents written\n",
      "2000 documents written\n",
      "3000 documents written\n",
      "4000 documents written\n",
      "5000 documents written\n",
      "6000 documents written\n",
      "7000 documents written\n",
      "8000 documents written\n",
      "9000 documents written\n",
      "10000 documents written\n",
      "11000 documents written\n",
      "12000 documents written\n",
      "13000 documents written\n",
      "14000 documents written\n",
      "15000 documents written\n",
      "16000 documents written\n",
      "17000 documents written\n",
      "18000 documents written\n",
      "19000 documents written\n",
      "20000 documents written\n",
      "21000 documents written\n",
      "22000 documents written\n",
      "23000 documents written\n",
      "24000 documents written\n",
      "1000 documents loaded\n",
      "2000 documents loaded\n",
      "3000 documents loaded\n",
      "4000 documents loaded\n",
      "5000 documents loaded\n",
      "6000 documents loaded\n",
      "7000 documents loaded\n",
      "8000 documents loaded\n",
      "9000 documents loaded\n",
      "10000 documents loaded\n",
      "11000 documents loaded\n",
      "12000 documents loaded\n",
      "13000 documents loaded\n",
      "14000 documents loaded\n",
      "15000 documents loaded\n",
      "16000 documents loaded\n",
      "17000 documents loaded\n",
      "18000 documents loaded\n",
      "19000 documents loaded\n",
      "20000 documents loaded\n",
      "21000 documents loaded\n",
      "22000 documents loaded\n",
      "23000 documents loaded\n",
      "24000 documents loaded\n",
      "Corpus(documents=25000, tokens=77976, words=5750635))\n",
      "1000 documents written\n",
      "2000 documents written\n",
      "3000 documents written\n",
      "4000 documents written\n",
      "5000 documents written\n",
      "6000 documents written\n",
      "7000 documents written\n",
      "8000 documents written\n",
      "9000 documents written\n",
      "10000 documents written\n",
      "11000 documents written\n",
      "12000 documents written\n",
      "13000 documents written\n",
      "14000 documents written\n",
      "15000 documents written\n",
      "16000 documents written\n",
      "17000 documents written\n",
      "18000 documents written\n",
      "19000 documents written\n",
      "20000 documents written\n",
      "21000 documents written\n",
      "22000 documents written\n",
      "23000 documents written\n",
      "24000 documents written\n"
     ]
    }
   ],
   "source": [
    "vocabulary = Encoder.open('movie-review-HW2/aclImdb/imdb.vocab')\n",
    "print(vocabulary)\n",
    "\n",
    "train_corpus = Corpus.open('movie-review-HW2/aclImdb/train/**/*.txt',\n",
    "    vocabulary=vocabulary,\n",
    "    verbose=True\n",
    ")\n",
    "print(train_corpus)\n",
    "train_corpus.write('movie-review-HW2/aclImdb/train-BOW.NB', verbose=True)\n",
    "\n",
    "test_corpus = Corpus.open('movie-review-HW2/aclImdb/test/**/*.txt',\n",
    "    vocabulary=vocabulary,\n",
    "    verbose=True\n",
    ")\n",
    "print(test_corpus)\n",
    "test_corpus.write('movie-review-HW2/aclImdb/test-BOW.NB', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the saved frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 documents loaded\n",
      "2000 documents loaded\n",
      "3000 documents loaded\n",
      "4000 documents loaded\n",
      "5000 documents loaded\n",
      "6000 documents loaded\n",
      "7000 documents loaded\n",
      "8000 documents loaded\n",
      "9000 documents loaded\n",
      "10000 documents loaded\n",
      "11000 documents loaded\n",
      "12000 documents loaded\n",
      "13000 documents loaded\n",
      "14000 documents loaded\n",
      "15000 documents loaded\n",
      "16000 documents loaded\n",
      "17000 documents loaded\n",
      "18000 documents loaded\n",
      "19000 documents loaded\n",
      "20000 documents loaded\n",
      "21000 documents loaded\n",
      "22000 documents loaded\n",
      "23000 documents loaded\n",
      "24000 documents loaded\n",
      "Corpus(documents=25000, tokens=87884, words=5871238))\n",
      "1000 documents loaded\n",
      "2000 documents loaded\n",
      "3000 documents loaded\n",
      "4000 documents loaded\n",
      "5000 documents loaded\n",
      "6000 documents loaded\n",
      "7000 documents loaded\n",
      "8000 documents loaded\n",
      "9000 documents loaded\n",
      "10000 documents loaded\n",
      "11000 documents loaded\n",
      "12000 documents loaded\n",
      "13000 documents loaded\n",
      "14000 documents loaded\n",
      "15000 documents loaded\n",
      "16000 documents loaded\n",
      "17000 documents loaded\n",
      "18000 documents loaded\n",
      "19000 documents loaded\n",
      "20000 documents loaded\n",
      "21000 documents loaded\n",
      "22000 documents loaded\n",
      "23000 documents loaded\n",
      "24000 documents loaded\n",
      "Corpus(documents=25000, tokens=77976, words=5750635))\n"
     ]
    }
   ],
   "source": [
    "labeler = Encoder(['pos', 'neg'])\n",
    "vocabulary = Encoder.open('movie-review-HW2/aclImdb/imdb.vocab')\n",
    "\n",
    "train_corpus = Corpus.open('movie-review-HW2/aclImdb/train-BOW.NB', frequencies=True, verbose=True)\n",
    "print(train_corpus)\n",
    "test_corpus = Corpus.open('movie-review-HW2/aclImdb/test-BOW.NB', frequencies=True, verbose=True) \n",
    "print(test_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 documents fitted\n",
      "2000 documents fitted\n",
      "3000 documents fitted\n",
      "4000 documents fitted\n",
      "5000 documents fitted\n",
      "6000 documents fitted\n",
      "7000 documents fitted\n",
      "8000 documents fitted\n",
      "9000 documents fitted\n",
      "10000 documents fitted\n",
      "11000 documents fitted\n",
      "12000 documents fitted\n",
      "13000 documents fitted\n",
      "14000 documents fitted\n",
      "15000 documents fitted\n",
      "16000 documents fitted\n",
      "17000 documents fitted\n",
      "18000 documents fitted\n",
      "19000 documents fitted\n",
      "20000 documents fitted\n",
      "21000 documents fitted\n",
      "22000 documents fitted\n",
      "23000 documents fitted\n",
      "24000 documents fitted\n",
      "Model(vocabulary=Encoder(tokens=89527, sample=['worships', 'macnee', 'air-conditioning', 'defends', 'protocols', 'filicide']), labeler=Encoder(tokens=2, sample=['pos', 'neg']))\n"
     ]
    }
   ],
   "source": [
    "model = Model(vocabulary, labeler, log=True)\n",
    "model.fit(train_corpus, train_corpus.labels(), verbose=True)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 documents predicted\n",
      "2000 documents predicted\n",
      "3000 documents predicted\n",
      "4000 documents predicted\n",
      "5000 documents predicted\n",
      "6000 documents predicted\n",
      "7000 documents predicted\n",
      "8000 documents predicted\n",
      "9000 documents predicted\n",
      "10000 documents predicted\n",
      "11000 documents predicted\n",
      "12000 documents predicted\n",
      "13000 documents predicted\n",
      "14000 documents predicted\n",
      "15000 documents predicted\n",
      "16000 documents predicted\n",
      "17000 documents predicted\n",
      "18000 documents predicted\n",
      "19000 documents predicted\n",
      "20000 documents predicted\n",
      "21000 documents predicted\n",
      "22000 documents predicted\n",
      "23000 documents predicted\n",
      "24000 documents predicted\n",
      "{'accuracy': 0.81464, 'confusion': [[9325, 3175], [1459, 11041]]}\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_corpus, verbose=True, debug=False)\n",
    "score = Metrics.score(test_corpus.labels(), labeler.decode(predictions), labeler)\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bdbc323321bfd8046cd6c0131103a4b074176d3dfb408b8d3ec0f56e167f360e"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit ('3.10.0': pyenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
