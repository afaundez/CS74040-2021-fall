{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/afaundez/CS74040-2021-fall/blob/homework-1/homework-1/part_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PART I:\n",
        "\n",
        "(10 points) Do exercise 3.4 from Chapter 3 in the textbook: [https://web.stanford.edu/~jurafsky/slp3/3.pdf](https://web.stanford.edu/~jurafsky/slp3/3.pdf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We are given the following corpus, modified from the one in the chapter:\n",
        "\n",
        "    <s> I am Sam </s>\n",
        "    <s> Sam I am </s>\n",
        "    <s> I am Sam </s>\n",
        "    <s> I do not like green eggs and Sam </s>\n",
        "\n",
        "Using a bigram language model with add-one smoothing, what is P(Sam | am)? Include \\<s> and \\</s> in your counts just like any other token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 292,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(count(am, sam) + 1) / (count(am) + |V|) = (2 + 1) / (3 + 11)  =  0.21428571428571427\n"
          ]
        }
      ],
      "source": [
        "p1_corpora = filenameToCorpora('p1.txt', startToken='<s>', stopToken='</s>')\n",
        "p1_unigrams, p1_bigrams = processGrams(p1_corpora)\n",
        "p1Model = SmoothBigramModel(p1_unigrams, p1_bigrams)\n",
        "result, equation = p1Model.bigramMLE('sam', 'am', log=False, verbose=False)\n",
        "print(equation, ' = ', result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 266,
      "metadata": {},
      "outputs": [],
      "source": [
        "sentences = ['<s> I am Sam </s>', '<s> Sam I am </s>', '<s> I am Sam </s>', '<s> I do not like green eggs and Sam </s>']\n",
        "sentences = [ sentence.split(' ') for sentence in sentences ]\n",
        "\n",
        "unigrams_count_by_unigram = {}\n",
        "for sentence in sentences:\n",
        "    for word in sentence:\n",
        "        if word not in unigrams_count_by_unigram:\n",
        "            unigrams_count_by_unigram[word] = 0\n",
        "        unigrams_count_by_unigram[word] += 1\n",
        "\n",
        "vocabulary = set(unigrams_count_by_unigram.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 267,
      "metadata": {},
      "outputs": [],
      "source": [
        "from itertools import tee\n",
        "\n",
        "def pairwise(iterable):\n",
        "    a, b = tee(iterable)\n",
        "    next(b, None)\n",
        "    return zip(a, b)\n",
        "\n",
        "bigrams_count_by_bigram = {}\n",
        "for sentence in sentences:\n",
        "    for bigram in pairwise(sentence):\n",
        "        if bigram not in bigrams_count_by_bigram:\n",
        "            bigrams_count_by_bigram[bigram] = 0\n",
        "        bigrams_count_by_bigram[bigram] += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 268,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.21428571428571427"
            ]
          },
          "execution_count": 268,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "MLE_probabilities_by_token_given_condition = {\n",
        "    (token, condition): (condition_token_count + 1) / (unigrams_count_by_unigram[condition] + len(vocabulary))\n",
        "    for (condition, token), condition_token_count in bigrams_count_by_bigram.items()\n",
        "}\n",
        "\n",
        "MLE_probabilities_by_token_given_condition = defaultdict(lambda: (1 / len(vocabulary)), MLE_probabilities_by_token_given_condition)\n",
        "\n",
        "MLE_probabilities_by_token_given_condition[('Sam', 'am')]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PART II:\n",
        "\n",
        "In this assignment, you will train several language models and will evaluate them on a test corpus. You can discuss in groups, but the homework is to be completed and submitted individually. Two files are provided with this assignment:\n",
        "\n",
        "1. train.txt\n",
        "2. test.txt\n",
        "\n",
        "Each file is a collection of texts, one sentence per line. train.txt contains 10,000 sentences from the NewsCrawl corpus. You will use this corpus to train the language models. The test corpus test.txt is from the same domain and will be used to evaluate the language models that you trained."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.1 PRE-PROCESSING\n",
        "\n",
        "Prior to training, please complete the following pre-processing steps:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. Pad each sentence in the training and test corpora with start and end symbols (you can use \\<s> and \\</s>, respectively)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 366,
      "metadata": {},
      "outputs": [],
      "source": [
        "def loadSentences(filename):\n",
        "    with open(filename, 'r') as f:\n",
        "        corpora = f.read().strip()\n",
        "        return [ sentence.strip().split(' ') for sentence in corpora.split('\\n') ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 371,
      "metadata": {
        "id": "4IS01d8vtbI0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TRAIN ['Man', 'charged', 'over', 'drugs', 'seizure']\n",
            "TEST ['The', 'road', 'was', 'pitted', 'with', 'tank', 'treads', '.']\n"
          ]
        }
      ],
      "source": [
        "train_corpora = loadSentences('train.txt')\n",
        "print('TRAIN', train_corpora[1])\n",
        "assert len(train_corpora) == 100000, f'train must have 10000 sentences, got {len(train_corpora)} instead'\n",
        "\n",
        "test_corpora = loadSentences('test.txt')\n",
        "print('TEST', test_corpora[2])\n",
        "assert len(test_corpora) == 100, f'test must have 100 sentences, got {len(test_corpora)} instead'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 372,
      "metadata": {},
      "outputs": [],
      "source": [
        "def padSentence(sentence, startToken='<s>', stopToken='</s>'):\n",
        "    return [startToken] + sentence + [stopToken]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 373,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TRAIN ['Man', 'charged', 'over', 'drugs', 'seizure'] -> ['<s>', 'Man', 'charged', 'over', 'drugs', 'seizure', '</s>']\n",
            "TEST ['If', 'you', 'have', 'owned', 'the', 'property', 'for', 'more', 'than', 'three', 'years', ',', 'you', 'can', 'apply', 'for', '\"', 'taper', 'relief', ',', '\"', 'by', 'which', 'you', 'can', 'reduce', 'any', 'taxable', 'gain', 'by', '5%', 'for', 'each', 'year', 'of', 'ownership', ',', 'up', 'to', 'a', 'maximum', '40%', '.'] -> ['<s>', 'The', 'road', 'was', 'pitted', 'with', 'tank', 'treads', '.', '</s>']\n"
          ]
        }
      ],
      "source": [
        "train_padded_corpora = [ padSentence(sentence) for sentence in train_corpora ]\n",
        "print('TRAIN', train_corpora[1], '->', train_padded_corpora[1])\n",
        "\n",
        "test_padded_corpora = [padSentence(sentence) for sentence in test_corpora]\n",
        "print('TEST', test_corpora[1], '->', test_padded_corpora[2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Lowercase all words in the training and test corpora. Note that the data already has been tokenized (i.e. the punctuation has been split off words)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 374,
      "metadata": {},
      "outputs": [],
      "source": [
        "def lowerSentence(sentence):\n",
        "    return [ word.lower() for word in sentence ]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 376,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TRAIN ['<s>', 'Man', 'charged', 'over', 'drugs', 'seizure', '</s>'] -> ['<s>', 'man', 'charged', 'over', 'drugs', 'seizure', '</s>']\n",
            "TEST ['<s>', 'The', 'road', 'was', 'pitted', 'with', 'tank', 'treads', '.', '</s>'] -> ['<s>', 'the', 'road', 'was', 'pitted', 'with', 'tank', 'treads', '.', '</s>']\n"
          ]
        }
      ],
      "source": [
        "train_lowercased_padded_corpora = [ lowerSentence(sentence) for sentence in train_padded_corpora ]\n",
        "print('TRAIN', train_padded_corpora[1], '->', train_lowercased_padded_corpora[1])\n",
        "assert ' '.join(train_lowercased_padded_corpora[1]) == '<s> man charged over drugs seizure </s>', f'train_lowercased_padded_corpora[1] must be \"<s> man charged over drugs seizure </s>\", got {train_lowercased_padded_corpora[1]} instead'\n",
        "train_lowercased_padded_vocabulary = set(word for sentence in train_lowercased_padded_corpora for word in sentence)\n",
        "\n",
        "test_lowercased_padded_corpora = [ lowerSentence(sentence) for sentence in test_padded_corpora ]\n",
        "print('TEST', test_padded_corpora[2], '->', test_lowercased_padded_corpora[2])\n",
        "assert ' '.join(test_lowercased_padded_corpora[2]) == '<s> the road was pitted with tank treads . </s>', f'test_lowercased_padded_corpora[2] must be \"<s> the road was pitted with tank treads . </s>\", got {lowercased_padded_test[1]} instead'\n",
        "lowercased_padded_test_vocabulary = set(word for sentence in test_lowercased_padded_corpora for word in sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Replace all words occurring in the training data once with the token \\<unk>. Everyword in the test data not seen in training should be treated as \\<unk>."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 377,
      "metadata": {},
      "outputs": [],
      "source": [
        "from itertools import tee\n",
        "\n",
        "def pairwise(iterable):\n",
        "    a, b = tee(iterable)\n",
        "    next(b, None)\n",
        "    return zip(a, b)\n",
        "\n",
        "def sentenceToWords(sentence, startToken='<s>', stopToken='</s>', unknownToken='<unk>', unknownWords=set(), knownWords=set()):\n",
        "    words = sentence.strip().lower().split(' ')\n",
        "    words = [\n",
        "        word if (len(knownWords) > 0 and word in knownWords) or (word not in unknownWords) else unknownToken\n",
        "        for word in words\n",
        "    ]\n",
        "    print(words)\n",
        "    return [startToken, *words, stopToken]\n",
        "\n",
        "def replaceWordsInSentence(sentence, wordsForReplacing=[], replacingToken='<unk>'):\n",
        "    return [\n",
        "        word if word not in wordsForReplacing else replacingToken\n",
        "        for word in sentence\n",
        "    ]\n",
        "\n",
        "def filenameToCorpora(filename, startToken='<s>', stopToken='</s>', unknownToken='<unk>', unknownWords=[]):\n",
        "    return [\n",
        "        replaceWordsInSentence(\n",
        "            lowerSentence(\n",
        "                padSentence(sentence, startToken, stopToken)),\n",
        "            wordsForReplacing=unknownWords, replacingToken=unknownToken)\n",
        "        for sentence in loadSentences(filename)\n",
        "    ]\n",
        "\n",
        "def processGrams(corpora):\n",
        "    unigrams = {}\n",
        "    bigrams = {}\n",
        "    for sentence in corpora:\n",
        "        for (condition, word) in pairwise(sentence):\n",
        "            if condition not in bigrams:\n",
        "                bigrams[condition] = {}\n",
        "            if word not in bigrams[condition]:\n",
        "                bigrams[condition][word] = 0\n",
        "            bigrams[condition][word] += 1\n",
        "        for token_type in sentence:\n",
        "            if token_type not in unigrams:\n",
        "                unigrams[token_type] = 0\n",
        "            unigrams[token_type] += 1\n",
        "    return unigrams, bigrams\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 378,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_corpora = filenameToCorpora('train.txt', startToken='<s>', stopToken='</s>')\n",
        "train_unigrams, train_bigrams = processGrams(train_corpora)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 342,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total sentences 100000\n",
            "total words 2368210\n",
            "total words with start/stop 2568210\n",
            "total unigrams types 83043\n",
            "total unigrams types with start/stop 83045\n",
            "total unigrams words 2368210\n",
            "total unigrams words with start/stop 2568210\n",
            "total bigrams types with start/stop 83044\n",
            "total bigrams words with start/stop 809973\n"
          ]
        }
      ],
      "source": [
        "print('total sentences', len(train_corpora))\n",
        "\n",
        "print('total words', sum(len([word for word in sentence if word not in {'<s>', '</s>'}]) for sentence in train_corpora))\n",
        "print('total words with start/stop', sum(count for count  in train_unigrams.values()))\n",
        "\n",
        "print('total unigrams types', len([ count for unigram, count in train_unigrams.items() if unigram not in {'<s>', '</s>'} ]))\n",
        "print('total unigrams types with start/stop', len(train_unigrams))\n",
        "\n",
        "print('total unigrams words', sum(count for unigram, count in train_unigrams.items() if unigram not in {'<s>', '</s>'}))\n",
        "print('total unigrams words with start/stop', sum(train_unigrams.values()))\n",
        "\n",
        "print('total bigrams types with start/stop', len(train_bigrams))\n",
        "print('total bigrams words with start/stop', sum(len(condition_word.values()) for condition_word in train_bigrams.values()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 379,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_corpora = filenameToCorpora('test.txt', startToken='<s>', stopToken='</s>')\n",
        "test_unigrams, test_bigrams = processGrams(test_corpora)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 380,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total sentences 100\n",
            "total words 2669\n",
            "total words with start/stop 2869\n",
            "total unigrams types 1247\n",
            "total unigrams types with start/stop 1249\n",
            "total unigrams words 2669\n",
            "total unigrams words with start/stop 2869\n",
            "total bigrams types with start/stop 1248\n",
            "total bigrams words with start/stop 2421\n"
          ]
        }
      ],
      "source": [
        "print('total sentences', len(test_corpora))\n",
        "\n",
        "print('total words', sum(len([word for word in sentence if word not in {'<s>', '</s>'}]) for sentence in test_corpora))\n",
        "print('total words with start/stop', sum(count for count  in test_unigrams.values()))\n",
        "\n",
        "print('total unigrams types', len([ count for unigram, count in test_unigrams.items() if unigram not in {'<s>', '</s>'} ]))\n",
        "print('total unigrams types with start/stop', len(test_unigrams))\n",
        "\n",
        "print('total unigrams words', sum(count for unigram, count in test_unigrams.items() if unigram not in {'<s>', '</s>'}))\n",
        "print('total unigrams words with start/stop', sum(test_unigrams.values()))\n",
        "\n",
        "print('total bigrams types with start/stop', len(test_bigrams))\n",
        "print('total bigrams words with start/stop', sum(len(condition_word.values()) for condition_word in test_bigrams.values()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 381,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_only_unigrams = { unigram: count for unigram, count in test_unigrams.items() if unigram not in train_unigrams }\n",
        "\n",
        "test_only_bigrams = {}\n",
        "for condition, word_count in test_bigrams.items():\n",
        "    if condition not in train_bigrams:\n",
        "        test_only_bigrams[condition] = word_count\n",
        "    else:\n",
        "        for word, count in word_count.items():\n",
        "            if word not in train_bigrams[condition]:\n",
        "                if condition not in test_only_bigrams:\n",
        "                    test_only_bigrams[condition] = {}\n",
        "                test_only_bigrams[condition][word] = count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 382,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "only test unigrams types 45\n",
            "only test unigrams words 46\n",
            "only test bigram types 722\n",
            "only test bigram words 725\n"
          ]
        }
      ],
      "source": [
        "print('only test unigrams types', len(test_only_unigrams.keys()))\n",
        "print('only test unigrams words', sum(test_only_unigrams.values()))\n",
        "\n",
        "print('only test bigram types', sum(len(token_count.values()) for token_count in test_only_bigrams.values()))\n",
        "print('only test bigram words', sum(sum(token_count.values()) for token_count in test_only_bigrams.values()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 383,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_once_unigrams = { word: count for word, count in train_unigrams.items() if count == 1 }\n",
        "\n",
        "train_corpora_with_replacing = filenameToCorpora('train.txt', startToken='<s>', stopToken='</s>', unknownToken='<unk>', unknownWords=set(train_once_unigrams.keys()))\n",
        "train_unigrams_with_replacing, train_bigrams_with_replacing = processGrams(train_corpora_with_replacing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 384,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total sentences 100000\n",
            "total words 2368210\n",
            "total words with start/stop 2568210\n",
            "total unigrams types 41737\n",
            "total unigrams types with start/stop 41739\n",
            "total unigrams words 2368210\n",
            "total unigrams words with start/stop 2568210\n",
            "total bigrams types with start/stop 41738\n",
            "total bigrams words with start/stop 742294\n"
          ]
        }
      ],
      "source": [
        "print('total sentences', len(train_corpora_with_replacing))\n",
        "\n",
        "print('total words', sum(len([word for word in sentence if word not in {'<s>', '</s>'}]) for sentence in train_corpora_with_replacing))\n",
        "print('total words with start/stop', sum(count for count  in train_unigrams_with_replacing.values()))\n",
        "\n",
        "print('total unigrams types', len([ count for unigram, count in train_unigrams_with_replacing.items() if unigram not in {'<s>', '</s>'} ]))\n",
        "print('total unigrams types with start/stop', len(train_unigrams_with_replacing))\n",
        "\n",
        "print('total unigrams words', sum(count for unigram, count in train_unigrams_with_replacing.items() if unigram not in {'<s>', '</s>'}))\n",
        "print('total unigrams words with start/stop', sum(train_unigrams_with_replacing.values()))\n",
        "\n",
        "print('total bigrams types with start/stop', len(train_bigrams_with_replacing))\n",
        "print('total bigrams words with start/stop', sum(len(condition_word.values()) for condition_word in train_bigrams_with_replacing.values()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 385,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100\n",
            "1175\n",
            "2869\n",
            "2365\n",
            "2769\n"
          ]
        }
      ],
      "source": [
        "train_once_test_only_unigrams = set(train_once_unigrams.keys()).union(set(test_only_unigrams.keys()))\n",
        "\n",
        "test_corpora_with_replacing = filenameToCorpora('test.txt', startToken='<s>', stopToken='</s>', unknownToken='<unk>', unknownWords=train_once_test_only_unigrams)\n",
        "test_unigrams_with_replacing, test_bigrams_with_replacing = processGrams(test_corpora_with_replacing)\n",
        "print(len(test_corpora_with_replacing))\n",
        "print(len(test_unigrams_with_replacing))\n",
        "print(sum(test_unigrams_with_replacing.values()))\n",
        "print(sum(len(condition_word.values()) for condition_word in test_bigrams_with_replacing.values()))\n",
        "print(sum(sum(condition_word.values()) for condition_word in test_bigrams_with_replacing.values()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.2 TRAINING THE MODELS\n",
        "\n",
        "Please use train.txt to train the following language models:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. A unigram maximum likelihood model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 411,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['man', 'charged', 'over', 'drugs']\n",
            "P(\\texttt{<s>}) &= \\frac{count(\\texttt{<s>})}{count()} = \\frac{100000}{2568210} = 0.03893762581720342\\\\\n",
            "P(\\texttt{man}) &= \\frac{count(\\texttt{man})}{count()} = \\frac{942}{2568210} = 0.00036679243519805626\\\\\n",
            "P(\\texttt{charged}) &= \\frac{count(\\texttt{charged})}{count()} = \\frac{245}{2568210} = 9.539718325214838e-05\\\\\n",
            "P(\\texttt{over}) &= \\frac{count(\\texttt{over})}{count()} = \\frac{2876}{2568210} = 0.0011198461185027704\\\\\n",
            "P(\\texttt{drugs}) &= \\frac{count(\\texttt{drugs})}{count()} = \\frac{275}{2568210} = 0.00010707847099730941\\\\\n",
            "P(\\texttt{</s>}) &= \\frac{count(\\texttt{</s>})}{count()} = \\frac{100000}{2568210} = 0.03893762581720342\\\\\n",
            "P(\\texttt{man charged over drugs}) &= P(\\texttt{<s>}) \\times P(\\texttt{man}) \\times P(\\texttt{charged}) \\times P(\\texttt{over}) \\times P(\\texttt{drugs}) \\times P(\\texttt{</s>})\\\\ &= 0.03893762581720342 \\times 0.00036679243519805626 \\times 9.539718325214838e-05 \\times 0.0011198461185027704 \\times 0.00010707847099730941 \\times 0.03893762581720342 \\\\ &= 6.361438993281194e-18\n",
            "\n",
            "['man', 'charged', 'over', 'drugs']\n",
            "\\log_{2} (P(\\texttt{<s>})) &= \\log_{2} (\\frac{count(\\texttt{<s>})}{count()}) = \\log_{2} (\\frac{100000}{2568210}) = -3.2457942511792446\\\\\n",
            "\\log_{2} (P(\\texttt{man})) &= \\log_{2} (\\frac{count(\\texttt{man})}{count()}) = \\log_{2} (\\frac{942}{2568210}) = -7.91071444157311\\\\\n",
            "\\log_{2} (P(\\texttt{charged})) &= \\log_{2} (\\frac{count(\\texttt{charged})}{count()}) = \\log_{2} (\\frac{245}{2568210}) = -9.257461505604747\\\\\n",
            "\\log_{2} (P(\\texttt{over})) &= \\log_{2} (\\frac{count(\\texttt{over})}{count()}) = \\log_{2} (\\frac{2876}{2568210}) = -6.794563997308535\\\\\n",
            "\\log_{2} (P(\\texttt{drugs})) &= \\log_{2} (\\frac{count(\\texttt{drugs})}{count()}) = \\log_{2} (\\frac{275}{2568210}) = -9.141948618482902\\\\\n",
            "\\log_{2} (P(\\texttt{</s>})) &= \\log_{2} (\\frac{count(\\texttt{</s>})}{count()}) = \\log_{2} (\\frac{100000}{2568210}) = -3.2457942511792446\\\\\n",
            "\\log_{2}(P(\\texttt{man charged over drugs})) &= \\log_{2} (P(\\texttt{<s>})) + \\log_{2} (P(\\texttt{man})) + \\log_{2} (P(\\texttt{charged})) + \\log_{2} (P(\\texttt{over})) + \\log_{2} (P(\\texttt{drugs})) + \\log_{2} (P(\\texttt{</s>}))\\\\ &= -3.2457942511792446 + -7.91071444157311 + -9.257461505604747 + -6.794563997308535 + -9.141948618482902 + -3.2457942511792446 \\\\ &= -39.59627706532778\n",
            "\n",
            "['man', 'charged', 'over', 'drugs', 'lalalllala']\n",
            "P(\\texttt{<s>}) &= \\frac{count(\\texttt{<s>})}{count()} = \\frac{100000}{2568210} = 0.03893762581720342\\\\\n",
            "P(\\texttt{man}) &= \\frac{count(\\texttt{man})}{count()} = \\frac{942}{2568210} = 0.00036679243519805626\\\\\n",
            "P(\\texttt{charged}) &= \\frac{count(\\texttt{charged})}{count()} = \\frac{245}{2568210} = 9.539718325214838e-05\\\\\n",
            "P(\\texttt{over}) &= \\frac{count(\\texttt{over})}{count()} = \\frac{2876}{2568210} = 0.0011198461185027704\\\\\n",
            "P(\\texttt{drugs}) &= \\frac{count(\\texttt{drugs})}{count()} = \\frac{275}{2568210} = 0.00010707847099730941\\\\\n",
            "P(\\texttt{lalalllala}) &= \\frac{count(\\texttt{lalalllala})}{count()} = \\frac{0}{2568210} = 0\\\\\n",
            "P(\\texttt{</s>}) &= \\frac{count(\\texttt{</s>})}{count()} = \\frac{100000}{2568210} = 0.03893762581720342\\\\\n",
            "P(\\texttt{man charged over drugs lalalllala}) &= P(\\texttt{<s>}) \\times P(\\texttt{man}) \\times P(\\texttt{charged}) \\times P(\\texttt{over}) \\times P(\\texttt{drugs}) \\times P(\\texttt{lalalllala}) \\times P(\\texttt{</s>})\\\\ &= 0.03893762581720342 \\times 0.00036679243519805626 \\times 9.539718325214838e-05 \\times 0.0011198461185027704 \\times 0.00010707847099730941 \\times 0 \\times 0.03893762581720342 \\\\ &= 0.0\n",
            "\n",
            "['man', 'charged', 'over', 'drugs', 'lalalllala']\n",
            "\\log_{2} (P(\\texttt{<s>})) &= \\log_{2} (\\frac{count(\\texttt{<s>})}{count()}) = \\log_{2} (\\frac{100000}{2568210}) = -3.2457942511792446\\\\\n",
            "\\log_{2} (P(\\texttt{man})) &= \\log_{2} (\\frac{count(\\texttt{man})}{count()}) = \\log_{2} (\\frac{942}{2568210}) = -7.91071444157311\\\\\n",
            "\\log_{2} (P(\\texttt{charged})) &= \\log_{2} (\\frac{count(\\texttt{charged})}{count()}) = \\log_{2} (\\frac{245}{2568210}) = -9.257461505604747\\\\\n",
            "\\log_{2} (P(\\texttt{over})) &= \\log_{2} (\\frac{count(\\texttt{over})}{count()}) = \\log_{2} (\\frac{2876}{2568210}) = -6.794563997308535\\\\\n",
            "\\log_{2} (P(\\texttt{drugs})) &= \\log_{2} (\\frac{count(\\texttt{drugs})}{count()}) = \\log_{2} (\\frac{275}{2568210}) = -9.141948618482902\\\\\n",
            "\\log_{2} (P(\\texttt{lalalllala})) &= \\log_{2} (\\frac{count(\\texttt{lalalllala})}{count()}) = \\log_{2} (\\frac{0}{2568210}) = -inf\\\\\n",
            "\\log_{2} (P(\\texttt{</s>})) &= \\log_{2} (\\frac{count(\\texttt{</s>})}{count()}) = \\log_{2} (\\frac{100000}{2568210}) = -3.2457942511792446\\\\\n",
            "\\log_{2}(P(\\texttt{man charged over drugs lalalllala})) &= \\log_{2} (P(\\texttt{<s>})) + \\log_{2} (P(\\texttt{man})) + \\log_{2} (P(\\texttt{charged})) + \\log_{2} (P(\\texttt{over})) + \\log_{2} (P(\\texttt{drugs})) + \\log_{2} (P(\\texttt{lalalllala})) + \\log_{2} (P(\\texttt{</s>}))\\\\ &= -3.2457942511792446 + -7.91071444157311 + -9.257461505604747 + -6.794563997308535 + -9.141948618482902 + -inf + -3.2457942511792446 \\\\ &= -inf\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "\n",
        "class UnigramModel:\n",
        "    def __init__(self, unigrams):\n",
        "        self.unigrams = unigrams\n",
        "    \n",
        "    def unigramMLE(self, unigram, log=False, verbose=False):\n",
        "        denominator = sum(self.unigrams.values())\n",
        "        if unigram in self.unigrams:\n",
        "            numerator = self.unigrams[unigram]\n",
        "            result = numerator / denominator\n",
        "        else:\n",
        "            numerator = 0\n",
        "            result = 0\n",
        "        if log:\n",
        "            result = math.log(result) if result > 0 else -math.inf\n",
        "            leftSide = '\\log_{2} (\\\\frac{count(\\\\texttt{'+ unigram + '})}{count()})'\n",
        "            rightSide = '\\log_{2} (\\\\frac{' + str(numerator) +  '}{' + str(denominator) + '})'\n",
        "            key = '\\log_{2} (P(\\\\texttt{'+ unigram + '}))'\n",
        "        else:\n",
        "            leftSide = '\\\\frac{count(\\\\texttt{'+ unigram + '})}{count()}'\n",
        "            rightSide = '\\\\frac{' + str(numerator) +  '}{' + str(denominator) + '}'\n",
        "            key = 'P(\\\\texttt{'+ unigram + '})'\n",
        "        fullEquation = f'{leftSide} = {rightSide}'\n",
        "        if verbose:\n",
        "            print(key +  ' &= ' + fullEquation +  ' = ' + str(result) + '\\\\\\\\')\n",
        "        return result, key, fullEquation\n",
        "\n",
        "    def sentenceMLE(self, sentence, log=False, verbose=False):\n",
        "        words = sentenceToWords(sentence, knownWords=set(self.unigrams.keys()))\n",
        "        equation = {}\n",
        "        for unigram in words:\n",
        "            probability, probability_key, probability_equation = self.unigramMLE(unigram, log=log, verbose=verbose)\n",
        "            equation[probability_key] = probability\n",
        "        if log:\n",
        "            result = sum(equation.values())\n",
        "            key = '\\log_{2}(P(\\\\texttt{'+ sentence + '}))'\n",
        "            operatorSymbol = ' + '\n",
        "        else:\n",
        "            result = math.prod(equation.values())\n",
        "            key = 'P(\\\\texttt{'+ sentence + '})'\n",
        "            operatorSymbol = ' \\\\times '\n",
        "        leftSide = operatorSymbol.join(equation.keys())\n",
        "        rightSide = operatorSymbol.join([ str(v) for v in equation.values()])\n",
        "        fullEquation = key + ' &= ' + leftSide + '\\\\\\\\ &= ' + rightSide\n",
        "        if verbose:\n",
        "            print(f\"{fullEquation} \\\\\\\\ &= {result}\\n\")\n",
        "        return result, fullEquation\n",
        "\n",
        "unigramModel = UnigramModel(train_unigrams_with_replacing)\n",
        "output = unigramModel.sentenceMLE('man charged over drugs', verbose=True)\n",
        "output = unigramModel.sentenceMLE('man charged over drugs', verbose=True, log=True)\n",
        "output = unigramModel.sentenceMLE('man charged over drugs lalalllala', verbose=True)\n",
        "output = unigramModel.sentenceMLE('man charged over drugs lalalllala', verbose=True, log=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. A bigram maximum likelihood model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 282,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['man', 'charged', 'over', 'drugs', 'seizure']\n",
            "['man', 'charged', 'over', 'drugs', 'seizure']\n",
            "P(man | <s>) = count(<s>, man) / count(<s>) = 75 / 100000 = 0.00075\n",
            "P(charged | man) = count(man, charged) / count(man) = 7 / 942 = 0.0074309978768577496\n",
            "P(over | charged) = count(charged, over) / count(charged) = 7 / 245 = 0.02857142857142857\n",
            "P(drugs | over) = count(over, drugs) / count(over) = 2 / 2876 = 0.0006954102920723226\n",
            "P(seizure | drugs) = count(drugs, seizure) / count(drugs) = 1 / 275 = 0.0036363636363636364\n",
            "P(</s> | seizure) = count(seizure, </s>) / count(seizure) = 1 / 13 = 0.07692307692307693\n",
            "P(Man charged over drugs seizure) =  P(man | <s>) * P(charged | man) * P(over | charged) * P(drugs | over) * P(seizure | drugs) * P(</s> | seizure)  =  0.00075 * 0.0074309978768577496 * 0.02857142857142857 * 0.0006954102920723226 * 0.0036363636363636364 * 0.07692307692307693  =  3.097457984376298e-14\n",
            "\n",
            "['man', 'charged', 'over', 'drugs', 'seizure', 'lalalala']\n",
            "['man', 'charged', 'over', 'drugs', 'seizure', 'lalalala']\n",
            "P(man | <s>) = count(<s>, man) / count(<s>) = 75 / 100000 = 0.00075\n",
            "P(charged | man) = count(man, charged) / count(man) = 7 / 942 = 0.0074309978768577496\n",
            "P(over | charged) = count(charged, over) / count(charged) = 7 / 245 = 0.02857142857142857\n",
            "P(drugs | over) = count(over, drugs) / count(over) = 2 / 2876 = 0.0006954102920723226\n",
            "P(seizure | drugs) = count(drugs, seizure) / count(drugs) = 1 / 275 = 0.0036363636363636364\n",
            "P(lalalala | seizure) = count(seizure, lalalala) / count(seizure) = 0 / 0 = 0\n",
            "P(</s> | lalalala) = count(lalalala, </s>) / count(lalalala) = 0 / 0 = 0\n",
            "P(Man charged over drugs seizure lalalala) =  P(man | <s>) * P(charged | man) * P(over | charged) * P(drugs | over) * P(seizure | drugs) * P(lalalala | seizure) * P(</s> | lalalala)  =  0.00075 * 0.0074309978768577496 * 0.02857142857142857 * 0.0006954102920723226 * 0.0036363636363636364 * 0 * 0  =  0.0\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "execution_count": 282,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import math\n",
        "\n",
        "class BigramModel(UnigramModel):\n",
        "    def __init__(self, unigrams, bigrams):\n",
        "        super().__init__(unigrams)\n",
        "        self.bigrams = bigrams\n",
        "    \n",
        "    def bigramMLE(self, word, condition, log=False, verbose=False):\n",
        "        if condition in self.bigrams and word in self.bigrams[condition]:\n",
        "            bigramCount = self.bigrams[condition][word]\n",
        "            unigramCount = self.unigrams[condition]\n",
        "            probability = bigramCount / unigramCount\n",
        "        else:\n",
        "            bigramCount = 0\n",
        "            unigramCount = 0\n",
        "            probability = 0\n",
        "        equationText = f'count({condition}, {word}) / count({condition}) = {bigramCount} / {unigramCount}'\n",
        "        if verbose:\n",
        "            print(f'P({word} | {condition}) = ', equationText, ' = ', probability)\n",
        "        return probability, equationText\n",
        "\n",
        "    def sentenceMLE(self, sentence, log=False, verbose=False):\n",
        "        words = sentenceToWords(sentence)\n",
        "        bigrams = list(pairwise(words))\n",
        "\n",
        "        equation = {}\n",
        "        for condition, word in bigrams:\n",
        "            probability, probability_equation = self.bigramMLE(word, condition, log=log, verbose=verbose)\n",
        "            key = f'P({word} | {condition})'\n",
        "            equation[key] = probability\n",
        "            print(f'{key} = {probability_equation} = {probability}')\n",
        "\n",
        "        result = math.prod(equation.values())\n",
        "        print(f'P({sentence}) = ', ' * '.join(equation.keys()), ' = ', ' * '.join([ str(v) for v in equation.values()]), ' = ', result)\n",
        "        print()\n",
        "        return result\n",
        "\n",
        "bigramModel = BigramModel(train_unigrams_with_replacing, train_bigrams_with_replacing)\n",
        "bigramModel.sentenceMLE('Man charged over drugs seizure')\n",
        "bigramModel.sentenceMLE('Man charged over drugs seizure lalalala')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. A bigram model with Add-One smoothing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 283,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['man', 'charged', 'over', 'drugs', 'seizure']\n",
            "['man', 'charged', 'over', 'drugs', 'seizure']\n",
            "P(man | <s>) = (count(<s>, man) + 1) / (count(<s>) + |V|) = (75 + 1) / (100000 + 41739) = 0.0005361968124510544\n",
            "P(charged | man) = (count(man, charged) + 1) / (count(man) + |V|) = (7 + 1) / (942 + 41739) = 0.00018743703287176964\n",
            "P(over | charged) = (count(charged, over) + 1) / (count(charged) + |V|) = (7 + 1) / (245 + 41739) = 0.00019054878048780488\n",
            "P(drugs | over) = (count(over, drugs) + 1) / (count(over) + |V|) = (2 + 1) / (2876 + 41739) = 6.724195898240502e-05\n",
            "P(seizure | drugs) = (count(drugs, seizure) + 1) / (count(drugs) + |V|) = (1 + 1) / (275 + 41739) = 4.760317989241681e-05\n",
            "P(</s> | seizure) = (count(seizure, </s>) + 1) / (count(seizure) + |V|) = (1 + 1) / (13 + 41739) = 4.790189691511784e-05\n",
            "P(Man charged over drugs seizure) =  P(man | <s>) * P(charged | man) * P(over | charged) * P(drugs | over) * P(seizure | drugs) * P(</s> | seizure)  =  0.0005361968124510544 * 0.00018743703287176964 * 0.00019054878048780488 * 6.724195898240502e-05 * 4.760317989241681e-05 * 4.790189691511784e-05  =  2.936397435151234e-24\n",
            "\n",
            "['man', 'charged', 'over', 'drugs', 'seizure', 'lalalala']\n",
            "['man', 'charged', 'over', 'drugs', 'seizure', 'lalalala']\n",
            "P(man | <s>) = (count(<s>, man) + 1) / (count(<s>) + |V|) = (75 + 1) / (100000 + 41739) = 0.0005361968124510544\n",
            "P(charged | man) = (count(man, charged) + 1) / (count(man) + |V|) = (7 + 1) / (942 + 41739) = 0.00018743703287176964\n",
            "P(over | charged) = (count(charged, over) + 1) / (count(charged) + |V|) = (7 + 1) / (245 + 41739) = 0.00019054878048780488\n",
            "P(drugs | over) = (count(over, drugs) + 1) / (count(over) + |V|) = (2 + 1) / (2876 + 41739) = 6.724195898240502e-05\n",
            "P(seizure | drugs) = (count(drugs, seizure) + 1) / (count(drugs) + |V|) = (1 + 1) / (275 + 41739) = 4.760317989241681e-05\n",
            "P(lalalala | seizure) = (count(seizure, lalalala) + 1) / (count(seizure) + |V|) = (0 + 1) / (13 + 41739) = 2.395094845755892e-05\n",
            "P(</s> | lalalala) = (count(lalalala, </s>) + 1) / (count(lalalala) + |V|) = (0 + 1) / (0 + 41739) = 2.395840820335897e-05\n",
            "P(Man charged over drugs seizure lalalala) =  P(man | <s>) * P(charged | man) * P(over | charged) * P(drugs | over) * P(seizure | drugs) * P(lalalala | seizure) * P(</s> | lalalala)  =  0.0005361968124510544 * 0.00018743703287176964 * 0.00019054878048780488 * 6.724195898240502e-05 * 4.760317989241681e-05 * 2.395094845755892e-05 * 2.395840820335897e-05  =  3.517570419932478e-29\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "3.517570419932478e-29"
            ]
          },
          "execution_count": 283,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import math\n",
        "\n",
        "class SmoothBigramModel(BigramModel):\n",
        "    def bigramMLE(self, word, condition, log=False, verbose=False):\n",
        "        if condition in self.bigrams and word in self.bigrams[condition]:\n",
        "            numerator = self.bigrams[condition][word]\n",
        "        else:\n",
        "            numerator = 0\n",
        "        if condition in self.unigrams:\n",
        "            denominator = self.unigrams[condition]\n",
        "        else:\n",
        "            denominator = 0\n",
        "        vocab_size = len(self.unigrams.keys())\n",
        "        equation = f'(count({condition}, {word}) + 1) / (count({condition}) + |V|) = ({numerator} + 1) / ({denominator} + {vocab_size})'\n",
        "\n",
        "        result = (numerator + 1) / (denominator + vocab_size)\n",
        "        return result, equation\n",
        "\n",
        "smoothBigramModel = SmoothBigramModel(train_unigrams_with_replacing, train_bigrams_with_replacing)\n",
        "smoothBigramModel.sentenceMLE('Man charged over drugs seizure')\n",
        "smoothBigramModel.sentenceMLE('Man charged over drugs seizure lalalala')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. A bigram model with discounting and Katz backoff. Please use a discount constant of 0.5 (see lecture on smoothing)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 284,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['man', 'charged', 'over', 'drugs', 'seizure']\n",
            "['man', 'charged', 'over', 'drugs', 'seizure']\n",
            "P(man | <s>) = count*(<s>, man) / count(<s>) = 74.5 / 100000 = 0.000745\n",
            "P(charged | man) = count*(man, charged) / count(man) = 6.5 / 942 = 0.006900212314225053\n",
            "P(over | charged) = count*(charged, over) / count(charged) = 6.5 / 245 = 0.026530612244897958\n",
            "P(drugs | over) = count*(over, drugs) / count(over) = 1.5 / 2876 = 0.000521557719054242\n",
            "P(seizure | drugs) = count*(drugs, seizure) / count(drugs) = 0.5 / 275 = 0.0018181818181818182\n",
            "P(</s> | seizure) = count*(seizure, </s>) / count(seizure) = 0.5 / 13 = 0.038461538461538464\n",
            "P(Man charged over drugs seizure) =  P(man | <s>) * P(charged | man) * P(over | charged) * P(drugs | over) * P(seizure | drugs) * P(</s> | seizure)  =  0.000745 * 0.006900212314225053 * 0.026530612244897958 * 0.000521557719054242 * 0.0018181818181818182 * 0.038461538461538464  =  4.974304177587982e-15\n",
            "\n",
            "['man', 'charged', 'over', 'drugs', 'seizure', 'man']\n",
            "['man', 'charged', 'over', 'drugs', 'seizure', 'man']\n",
            "P(man | <s>) = count*(<s>, man) / count(<s>) = 74.5 / 100000 = 0.000745\n",
            "P(charged | man) = count*(man, charged) / count(man) = 6.5 / 942 = 0.006900212314225053\n",
            "P(over | charged) = count*(charged, over) / count(charged) = 6.5 / 245 = 0.026530612244897958\n",
            "P(drugs | over) = count*(over, drugs) / count(over) = 1.5 / 2876 = 0.000521557719054242\n",
            "P(seizure | drugs) = count*(drugs, seizure) / count(drugs) = 0.5 / 275 = 0.0018181818181818182\n",
            "alpha(seizure) = 1 - Sigma(count*(seizure, word) / count(seizure)) = 1 - 8.0 / 13 = 0.3846153846153846\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "too many values to unpack (expected 2)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-284-b55228b78f2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mkatzBigramModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKatzBigramModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_unigrams_with_replacing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_bigrams_with_replacing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mkatzBigramModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentenceMLE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Man charged over drugs seizure'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mkatzBigramModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentenceMLE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Man charged over drugs seizure man'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-282-4274fd39cc70>\u001b[0m in \u001b[0;36msentenceMLE\u001b[0;34m(self, sentence, log, verbose)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mequation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcondition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbigrams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mprobability\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobability_equation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbigramMLE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcondition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'P({word} | {condition})'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mequation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprobability\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-284-b55228b78f2d>\u001b[0m in \u001b[0;36mbigramMLE\u001b[0;34m(self, word, condition, log, verbose)\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0malpha_condition\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0malpha_numerator\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0malpha_denominator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'alpha({condition}) = 1 - Sigma(count*({condition}, word) / count({condition})) = 1 - {alpha_numerator} / {alpha_denominator} = {alpha_condition}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mnumerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munigramMLE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0mdenominator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munigramMLE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munigram\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0munigram\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munigrams\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0munigram\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mB_condition\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malpha_condition\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnumerator\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdenominator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
          ]
        }
      ],
      "source": [
        "class KatzBigramModel(BigramModel):\n",
        "    def __init__(self, unigrams, bigrams):\n",
        "        BigramModel.__init__(self, unigrams, bigrams)\n",
        "\n",
        "        self.bigrams_star = {}\n",
        "        # self.leftovers = {}\n",
        "        for condition, word_count in self.bigrams.items():\n",
        "            # self.leftovers[condition] = 1\n",
        "            if condition not in self.bigrams_star:\n",
        "                self.bigrams_star[condition] = {}\n",
        "            for word, count in word_count.items():\n",
        "                if word not in self.bigrams_star[condition]:\n",
        "                    self.bigrams_star[condition][word] = 0\n",
        "                self.bigrams_star[condition][word] = count - 0.5\n",
        "                # self.leftovers[condition] += 0.5\n",
        "\n",
        "    def bigramMLE(self, word, condition, log=False, verbose=False):\n",
        "        if condition in self.bigrams_star:\n",
        "            A_condition = set(self.bigrams_star[condition].keys())\n",
        "        else:\n",
        "            A_condition = set()\n",
        "\n",
        "        B_condition = set(self.unigrams.keys()) - A_condition\n",
        "        if word in A_condition:\n",
        "            numerator = self.bigrams_star[condition][word]\n",
        "            denominator = self.unigrams[condition]\n",
        "            result = numerator / denominator\n",
        "            return result, f'count*({condition}, {word}) / count({condition}) = {numerator} / {denominator}'\n",
        "        else:\n",
        "            alpha_numerator = sum(self.bigrams_star[condition].values())\n",
        "            alpha_denominator = self.unigrams[condition]\n",
        "            alpha_condition = 1 - alpha_numerator / alpha_denominator\n",
        "            print(f'alpha({condition}) = 1 - Sigma(count*({condition}, word) / count({condition})) = 1 - {alpha_numerator} / {alpha_denominator} = {alpha_condition}')\n",
        "            numerator, _ = self.unigramMLE(word)\n",
        "            denominator = sum(self.unigramMLE(unigram, log=log, verbose=verbose)[0] for unigram in self.unigrams if unigram in B_condition)\n",
        "            result = alpha_condition * numerator / denominator\n",
        "            return result, f'alpha({condition}) * P({word}) / Sigma_w_in_B(P(w)) = {alpha_condition} * {numerator} / {denominator}'\n",
        "\n",
        "katzBigramModel = KatzBigramModel(train_unigrams_with_replacing, train_bigrams_with_replacing)\n",
        "katzBigramModel.sentenceMLE('Man charged over drugs seizure')\n",
        "katzBigramModel.sentenceMLE('Man charged over drugs seizure man')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.3 QUESTIONS\n",
        "\n",
        "Please answer the questions below:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. (5 points) How many word types (unique words) are there in the training corpus? Please include the end-of-sentence padding symbol \\</s> and the unknown token \\<unk>. Do not include the start of sentence padding symbol \\<s>."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 345,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "word types in training 41738\n"
          ]
        }
      ],
      "source": [
        "excluded_unigrams =  {'<s>'}\n",
        "train_unigrams_with_replacing_without_start = set(train_unigrams_with_replacing.keys()) - excluded_unigrams\n",
        "print('word types in training', len(train_unigrams_with_replacing_without_start))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. (5 points) How many word tokens are there in the training corpus? Do not include the start of sentence padding symbol \\<s>."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 346,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "word tokens in training 2468210\n"
          ]
        }
      ],
      "source": [
        "excluded_unigrams =  {'<s>'}\n",
        "\n",
        "train_unigrams_with_replacing_without_start = sum([ value for word, value in train_unigrams_with_replacing.items() if word not in excluded_unigrams ])\n",
        "print('word tokens in training', train_unigrams_with_replacing_without_start)\n",
        "\n",
        "# test_unigrams_with_replacing_without_start = sum([ value for word, value in test_unigrams_with_replacing.items() if word not in {'<s>'} ])\n",
        "# print('test unigrams words count', test_unigrams_with_replacing_without_start)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. (10 points) What percentage of word tokens and word types in the test corpus did not occur in training (before you mapped the unknown words to \\<unk> in training and test data)? Please include the padding symbol \\</s> in your calculations. Do not include the start of sentence padding symbol \\<s>."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 359,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "unigrams types only in test 45\n",
            "unigrams types 1248\n",
            "percentage unigrams types only in test 3.6057692307692304\n",
            "unigrams words only in test 46\n",
            "unigrams words 2769\n",
            "percentage unigrams words only in test 1.6612495485734922\n"
          ]
        }
      ],
      "source": [
        "excluded_unigrams =  {'<s>'}\n",
        "test_only_unigrams_without_start = { word: count for word, count in test_only_unigrams.items() if word not in excluded_unigrams }\n",
        "test_unigrams_without_start = { word: count for word, count in test_unigrams.items() if word not in excluded_unigrams }\n",
        "print('unigrams types only in test', len(test_only_unigrams_without_start))\n",
        "print('unigrams types', len(test_unigrams_without_start))\n",
        "print('percentage unigrams types only in test', len(test_only_unigrams_without_start) / len(test_unigrams_without_start) * 100)\n",
        "\n",
        "\n",
        "print('unigrams words only in test', sum(test_only_unigrams_without_start.values()))\n",
        "print('unigrams words', sum(test_unigrams_without_start.values()))\n",
        "print('percentage unigrams words only in test', sum(test_only_unigrams_without_start.values()) / sum(test_unigrams_without_start.values()) * 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. (15 points) Now replace singletons in the training data with \\<unk> symbol and map words (in the test corpus) not observed in training to \\<unk>. What percentage of bigrams (bigram types and bigram tokens) in the test corpus did not occur in training (treat \\<unk> as a regular token that has been observed). Please include the padding symbol \\</s> in your calculations. Do not include the start of sentence padding symbol \\<s>."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 365,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bigrams types only in test 716\n",
            "bigrams types in test 2353\n",
            "percentage bigrams types only in test 30.429239269018275\n",
            "bigrams types only in test 719\n",
            "bigrams types in test 2669\n",
            "percentage bigrams types only in test 26.938928437617083\n"
          ]
        }
      ],
      "source": [
        "excluded_unigrams =  {'<s>'}\n",
        "\n",
        "test_only_bigrams_types_without_start_count = sum(len(word_count.keys()) for condition, word_count in test_only_bigrams.items() if condition not in excluded_unigrams)\n",
        "print('bigrams types only in test', test_only_bigrams_types_without_start_count)\n",
        "test_bigrams_types_without_start_count = sum(len(word_count.keys()) for condition, word_count in test_bigrams.items() if condition not in excluded_unigrams)\n",
        "print('bigrams types in test', test_bigrams_types_without_start_count)\n",
        "print('percentage bigrams types only in test', test_only_bigrams_types_without_start_count / test_bigrams_types_without_start_count * 100)\n",
        "\n",
        "test_only_bigrams_words_without_start_count = sum(sum(word_count.values()) for condition, word_count in test_only_bigrams.items() if condition not in excluded_unigrams)\n",
        "print('bigrams types only in test', test_only_bigrams_words_without_start_count)\n",
        "test_bigrams_words_without_start_count = sum(sum(word_count.values()) for condition, word_count in test_bigrams.items() if condition not in excluded_unigrams)\n",
        "print('bigrams types in test', test_bigrams_words_without_start_count)\n",
        "print('percentage bigrams types only in test', test_only_bigrams_words_without_start_count / test_bigrams_words_without_start_count * 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5. (15 points) Compute the log probability of the following sentence under the three models (ignore capitalization and pad each sentence as described above). Please list all of the parameters required to compute the probabilities and show the complete calculation. Which of the parameters have zero values under each model? Use log base 2 in your calculations. Map words not observed in the training corpus to the \\<unk> token.\n",
        "\n",
        "- I look forward to hearing your reply."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 231,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "P(<s>) = count(<s>) / count() = 100000 / 2568210 = 0.03893762581720342\n",
            "P(i) = count(i) / count() = 7339 / 2568210 = 0.0028576323587245593\n",
            "P(look) = count(look) / count() = 613 / 2568210 = 0.000238687646259457\n",
            "P(forward) = count(forward) / count() = 474 / 2568210 = 0.00018456434637354423\n",
            "P(to) = count(to) / count() = 53048 / 2568210 = 0.02065563174351007\n",
            "P(hearing) = count(hearing) / count() = 209 / 2568210 = 8.137963795795515e-05\n",
            "P(your) = count(your) / count() = 1217 / 2568210 = 0.00047387090619536564\n",
            "P(reply) = count(reply) / count() = 13 / 2568210 = 5.061891356236445e-06\n",
            "P(.) = count(.) / count() = 87894 / 2568210 = 0.03422383683577278\n",
            "P(</s>) = count(</s>) / count() = 100000 / 2568210 = 0.03893762581720342\n",
            "P(I look forward to hearing your reply .) =  P(<s>) * P(i) * P(look) * P(forward) * P(to) * P(hearing) * P(your) * P(reply) * P(.) * P(</s>)  =  0.03893762581720342 * 0.0028576323587245593 * 0.000238687646259457 * 0.00018456434637354423 * 0.02065563174351007 * 8.137963795795515e-05 * 0.00047387090619536564 * 5.061891356236445e-06 * 0.03422383683577278 * 0.03893762581720342  =  2.633776012975432e-29 \n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "2.633776012975432e-29"
            ]
          },
          "execution_count": 231,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "unigramModel.sentenceMLE('I look forward to hearing your reply .')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 232,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "P(i | <s>) = count(<s>, i) / count(<s>) = 2006 / 100000 = 0.02006\n",
            "P(look | i) = count(i, look) / count(i) = 15 / 7339 = 0.0020438751873552256\n",
            "P(forward | look) = count(look, forward) / count(look) = 34 / 613 = 0.05546492659053834\n",
            "P(to | forward) = count(forward, to) / count(forward) = 100 / 474 = 0.2109704641350211\n",
            "P(hearing | to) = count(to, hearing) / count(to) = 6 / 53048 = 0.00011310511235107827\n",
            "P(your | hearing) = count(hearing, your) / count(hearing) = 0 / 0 = 0\n",
            "P(reply | your) = count(your, reply) / count(your) = 0 / 0 = 0\n",
            "P(. | reply) = count(reply, .) / count(reply) = 0 / 0 = 0\n",
            "P(</s> | .) = count(., </s>) / count(.) = 82888 / 87894 = 0.9430450315152342\n",
            "P(I look forward to hearing your reply .) =  P(i | <s>) * P(look | i) * P(forward | look) * P(to | forward) * P(hearing | to) * P(your | hearing) * P(reply | your) * P(. | reply) * P(</s> | .)  =  0.02006 * 0.0020438751873552256 * 0.05546492659053834 * 0.2109704641350211 * 0.00011310511235107827 * 0 * 0 * 0 * 0.9430450315152342  =  0.0\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "execution_count": 232,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bigramModel.sentenceMLE('I look forward to hearing your reply .')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 234,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "P(i | <s>) = (count(<s>, i) + 1) / (count(<s>) + |V|) = (2006 + 1) / (100000 + 41739) = 0.014159828981437713\n",
            "P(look | i) = (count(i, look) + 1) / (count(i) + |V|) = (15 + 1) / (7339 + 41739) = 0.0003260116549166633\n",
            "P(forward | look) = (count(look, forward) + 1) / (count(look) + |V|) = (34 + 1) / (613 + 41739) = 0.0008264072534945221\n",
            "P(to | forward) = (count(forward, to) + 1) / (count(forward) + |V|) = (100 + 1) / (474 + 41739) = 0.002392627863454386\n",
            "P(hearing | to) = (count(to, hearing) + 1) / (count(to) + |V|) = (6 + 1) / (53048 + 41739) = 7.384978952809984e-05\n",
            "P(your | hearing) = (count(hearing, your) + 1) / (count(hearing) + |V|) = (0 + 1) / (209 + 41739) = 2.3839038809955182e-05\n",
            "P(reply | your) = (count(your, reply) + 1) / (count(your) + |V|) = (0 + 1) / (1217 + 41739) = 2.3279634975323588e-05\n",
            "P(. | reply) = (count(reply, .) + 1) / (count(reply) + |V|) = (0 + 1) / (13 + 41739) = 2.395094845755892e-05\n",
            "P(</s> | .) = (count(., </s>) + 1) / (count(.) + |V|) = (82888 + 1) / (87894 + 41739) = 0.6394128038385287\n",
            "P(I look forward to hearing your reply .) =  P(i | <s>) * P(look | i) * P(forward | look) * P(to | forward) * P(hearing | to) * P(your | hearing) * P(reply | your) * P(. | reply) * P(</s> | .)  =  0.014159828981437713 * 0.0003260116549166633 * 0.0008264072534945221 * 0.002392627863454386 * 7.384978952809984e-05 * 2.3839038809955182e-05 * 2.3279634975323588e-05 * 2.395094845755892e-05 * 0.6394128038385287  =  5.728997390142119e-30\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "5.728997390142119e-30"
            ]
          },
          "execution_count": 234,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "smoothBigramModel.sentenceMLE('I look forward to hearing your reply .')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 235,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "P(i | <s>) = count*(<s>, i) / count(<s>) = 2005.5 / 100000 = 0.020055\n",
            "P(look | i) = count*(i, look) / count(i) = 14.5 / 7339 = 0.001975746014443385\n",
            "P(forward | look) = count*(look, forward) / count(look) = 33.5 / 613 = 0.05464926590538336\n",
            "P(to | forward) = count*(forward, to) / count(forward) = 99.5 / 474 = 0.20991561181434598\n",
            "P(hearing | to) = count*(to, hearing) / count(to) = 5.5 / 53048 = 0.00010367968632182174\n",
            "alpha(hearing) = 1 - Sigma(count*(hearing, word) / count(hearing)) = 1 - 170.0 / 209 = 0.1866028708133971\n",
            "P(your | hearing) = alpha(hearing) * P(your) / Sigma_w_in_B(P(w)) = 0.1866028708133971 * 0.00047387090619536564 / 0.6730450391519687 = 0.00013138150695296243\n",
            "alpha(your) = 1 - Sigma(count*(your, word) / count(your)) = 1 - 874.5 / 1217 = 0.2814297452752671\n",
            "P(reply | your) = alpha(your) * P(reply) / Sigma_w_in_B(P(w)) = 0.2814297452752671 * 5.061891356236445e-06 / 0.8819099684217718 = 1.6153199827710787e-06\n",
            "alpha(reply) = 1 - Sigma(count*(reply, word) / count(reply)) = 1 - 10.0 / 13 = 0.23076923076923073\n",
            "P(. | reply) = alpha(reply) * P(.) / Sigma_w_in_B(P(w)) = 0.23076923076923073 * 0.03422383683577278 / 0.9201778670749203 = 0.00858291508974092\n",
            "P(</s> | .) = count*(., </s>) / count(.) = 82887.5 / 87894 = 0.9430393428447903\n",
            "P(I look forward to hearing your reply .) =  P(i | <s>) * P(look | i) * P(forward | look) * P(to | forward) * P(hearing | to) * P(your | hearing) * P(reply | your) * P(. | reply) * P(</s> | .)  =  0.020055 * 0.001975746014443385 * 0.05464926590538336 * 0.20991561181434598 * 0.00010367968632182174 * 0.00013138150695296243 * 1.6153199827710787e-06 * 0.00858291508974092 * 0.9430393428447903  =  8.095318855724841e-23\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "8.095318855724841e-23"
            ]
          },
          "execution_count": 235,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "katzBigramModel.sentenceMLE('I look forward to hearing your reply .')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6. (20 points) Compute the perplexity of the sentence above under each of the models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7. (20 points) Compute the perplexity of the entire test corpus under each of the models.Discuss the differences in the results you obtained."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPu+5nqDTetxfSaS64LcZBi",
      "include_colab_link": true,
      "name": "part-2.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    },
    "kernelspec": {
      "display_name": "Python 3.8.9 64-bit",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
